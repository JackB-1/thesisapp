import torch
import torch.nn as nn
import json

class SummingModel(nn.Module):
    def __init__(self):
        super(SummingModel, self).__init__()

    def forward(self, input_json):
        # Assuming input_json is a dictionary with the structure of the provided JSON
        max_sum = float('-inf')
        max_name = ''
        
        # Iterate over each key in the JSON except for the timestamp
        for key in input_json:
            if key == 'timestamp':
                continue
            current_sum = sum(input_json[key])
            if current_sum > max_sum:
                max_sum = current_sum
                max_name = key
        
        # Output the name of the array with the largest sum
        return max_name

# Instantiate the model
model = SummingModel()

# Example input (simplified for brevity)
input_json_simplified = {
    "timestamp": 1713205668679,
    "acc_x": [0.1, 0.2, 0.3],
    "acc_y": [0.4, 0.5, 0.6],
    "acc_z": [0.7, 0.8, 0.9],
    "gyro_x": [0.1, 0.2, 0.3],
    "gyro_y": [0.4, 0.5, 0.6],
    "gyro_z": [0.7, 0.8, 0.9]
}

input_json = {
    "timestamp":1713205668679,
    "acc_x": [0.18664683,0.14357449,0.1483603,0.12443122,0.10050214,0.13400285,0.13400285,0.17228939,0.11485959,0.16750357,0.12921704,0.15793194,0.14357449,0.16750357,0.12921704,0.13400285,0.12921704,0.110073775,0.16271774,0.1196454,0.11485959,0.18186101,0.13400285,0.14357449,0.08614469,0.18186101,0.09093051,0.17707519,0.15793194,0.16750357,0.13878867,0.17707519,0.10050214,0.14357449,0.12921704,0.10050214,0.14357449,0.14357449,0.14357449,0.12443122,0.12921704,0.12921704,0.16271774,0.15314612,0.16271774,0.1196454,0.17707519,0.13878867,0.14357449,0.10050214,0.14357449,0.16750357,0.14357449,0.17707519,0.110073775,0.16750357,0.10050214,0.16271774,0.13400285,0.12443122,0.13400285,0.15793194,0.17707519,0.11485959,0.13878867,0.17228939,0.13400285,0.13400285,0.110073775,0.15793194,0.08614469,0.09093051,0.1196454,0.16271774,0.19143265,0.20100428,0.071787246,0.09093051,0.10050214,0.12921704,0.10050214,0.15793194,0.13878867,0.12443122,0.16750357,0.14357449,0.1196454,0.11485959,0.17707519,0.1196454,0.09571633,0.12921704,0.16271774,0.12443122,0.105287954,0.12921704,0.1196454,0.10050214,0.13878867,0.12921704,0.10050214,0.13400285,0.15793194,0.1483603],
    "acc_y": [-2.1823323,-2.187118,-2.2206187,-2.2110472,-2.2014754,-2.2062612,-2.1775463,-2.2589052,-2.1727605,-2.2254045,-2.187118,-2.1488314,-2.2254045,-2.2110472,-2.239762,-2.2541194,-2.2014754,-2.2110472,-2.1919038,-2.2254045,-2.2541194,-2.2589052,-2.187118,-2.1823323,-2.2206187,-2.2110472,-2.187118,-2.1919038,-2.2062612,-2.1919038,-2.2493336,-2.2062612,-2.1966896,-2.1679747,-2.2301903,-2.1679747,-2.1392598,-2.2301903,-2.2254045,-2.2110472,-2.163189,-2.1775463,-2.1727605,-2.234976,-2.215833,-2.1823323,-2.1584032,-2.1679747,-2.2206187,-2.163189,-2.2206187,-2.2254045,-2.1823323,-2.1966896,-2.239762,-2.263691,-2.1919038,-2.2254045,-2.1679747,-2.187118,-2.2110472,-2.2301903,-2.2062612,-2.1775463,-2.2014754,-2.1919038,-2.187118,-2.187118,-2.2110472,-2.1823323,-2.2014754,-2.1727605,-2.187118,-2.1966896,-2.187118,-2.2110472,-2.215833,-2.1392598,-2.1727605,-2.215833,-2.187118,-2.234976,-2.1919038,-2.2062612,-2.1966896,-2.2254045,-2.2062612,-2.2301903,-2.1823323,-2.2301903,-2.263691,-2.2301903,-2.1966896,-2.1966896,-2.1823323,-2.2014754,-2.1823323,-2.234976,-2.2541194,-2.1679747,-2.1775463,-2.1727605,-2.2541194,-2.1966896],
    "acc_z": [9.715207,9.619491,9.633848,9.638634,9.672134,9.681706,9.629062,9.657777,9.681706,9.686492,9.681706,9.672134,9.657777,9.67692,9.619491,9.652991,9.648206,9.657777,9.595561,9.681706,9.614705,9.672134,9.629062,9.648206,9.662563,9.624276,9.672134,9.633848,9.624276,9.648206,9.629062,9.652991,9.619491,9.696064,9.667349,9.629062,9.686492,9.672134,9.643419,9.696064,9.67692,9.681706,9.624276,9.643419,9.638634,9.724778,9.624276,9.686492,9.70085,9.652991,9.67692,9.672134,9.652991,9.672134,9.652991,9.67692,9.662563,9.73435,9.619491,9.648206,9.629062,9.648206,9.652991,9.643419,9.652991,9.609919,9.662563,9.6003475,9.672134,9.667349,9.70085,9.633848,9.609919,9.662563,9.6912775,9.619491,9.648206,9.633848,9.629062,9.6912775,9.70085,9.6912775,9.657777,9.633848,9.686492,9.681706,9.667349,9.681706,9.652991,9.619491,9.619491,9.686492,9.643419,9.638634,9.648206,9.70085,9.581204,9.657777,9.609919,9.70085,9.609919,9.624276,9.595561,9.681706],
    "gyro_x": [-1.05,-1.05,-1.05,-1.12,-1.12,-1.19,-1.12,-1.19,-1.12,-1.12,-1.19,-1.19,-1.12,-1.05,-1.12,-1.12,-1.19,-1.12,-1.05,-1.12,-1.12,-0.98,-1.05,-1.19,-1.12,-1.05,-1.12,-1.12,-1.12,-1.05,-1.05,-1.12,-1.12,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-1.12,-1.12,-1.12,-1.19,-1.12,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-1.05,-1.05,-1.05,-1.19,-1.12,-1.19,-1.05,-1.05,-1.19,-1.19,-1.12,-1.19,-1.05,-1.05,-1.12,-1.05,-1.12,-1.12,-1.05,-1.05,-1.12,-1.12,-1.12,-1.19,-1.05,-1.12,-0.98,-1.05,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-0.98,-1.12,-1.05,-1.05,-1.12,-1.12,-1.05,-1.05,-0.98,-1.05,-1.12,-1.05,-1.12,-1.12,-1.19,-1.12,-1.05,-1.05,-1.12,-1.12],
    "gyro_y": [-1.05,-1.05,-1.05,-1.12,-1.12,-1.19,-1.12,-1.19,-1.12,-1.12,-1.19,-1.19,-1.12,-1.05,-1.12,-1.12,-1.19,-1.12,-1.05,-1.12,-1.12,-0.98,-1.05,-1.19,-1.12,-1.05,-1.12,-1.12,-1.12,-1.05,-1.05,-1.12,-1.12,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-1.12,-1.12,-1.12,-1.19,-1.12,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-1.05,-1.05,-1.05,-1.19,-1.12,-1.19,-1.05,-1.05,-1.19,-1.19,-1.12,-1.19,-1.05,-1.05,-1.12,-1.05,-1.12,-1.12,-1.05,-1.05,-1.12,-1.12,-1.12,-1.19,-1.05,-1.12,-0.98,-1.05,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-0.98,-1.12,-1.05,-1.05,-1.12,-1.12,-1.05,-1.05,-0.98,-1.05,-1.12,-1.05,-1.12,-1.12,-1.19,-1.12,-1.05,-1.05,-1.12,-1.12],
    "gyro_z": [-1.05,-1.05,-1.05,-1.12,-1.12,-1.19,-1.12,-1.19,-1.12,-1.12,-1.19,-1.19,-1.12,-1.05,-1.12,-1.12,-1.19,-1.12,-1.05,-1.12,-1.12,-0.98,-1.05,-1.19,-1.12,-1.05,-1.12,-1.12,-1.12,-1.05,-1.05,-1.12,-1.12,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-1.12,-1.12,-1.12,-1.19,-1.12,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-1.05,-1.05,-1.05,-1.19,-1.12,-1.19,-1.05,-1.05,-1.19,-1.19,-1.12,-1.19,-1.05,-1.05,-1.12,-1.05,-1.12,-1.12,-1.05,-1.05,-1.12,-1.12,-1.12,-1.19,-1.05,-1.12,-0.98,-1.05,-1.12,-1.05,-1.12,-1.12,-1.12,-1.12,-0.98,-1.12,-1.05,-1.05,-1.12,-1.12,-1.05,-1.05,-0.98,-1.05,-1.12,-1.05,-1.12,-1.12,-1.19,-1.12,-1.05,-1.05,-1.12,-1.12]
}



# Process the example input
output = model(input_json)
print(f"The array with the largest sum is: {output}")

# Save the model
torch.save(model, 'summing_model.pt')